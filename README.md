# MachineLearning
part 1 监督学习
已知输入样本集学习结果，建立预测模型，推演目标变量可能结果
目标变量一般有两种类型：标称型和数值型。

分类：
一 K-近邻算法
    对未知类别属性数据集中的每个点依次执行以下操作：
    1）计算已知类别数据集中的每个点到当前点的距离,
    需要归一化特征值，防止不同数量级的属性对分类影响，newvalue = (oldvalue-min)）/(max-min)
    2）按照距离递增排序
    3）选取与当前点最近的k个点
    4）确定前k个点的类别出现频率
    5）选择其中出现频率最高的点作为当前点的类别预测分类

二 决策树
    检测数据集中的每个子项是否属于同一个分类：
    如果是，则返回标签类
    否则
        寻找划分数据集的最好特征，（划分之后的信息增益最大，熵：信息的期望值,描述状态的不确定性，信息增益即熵减）
        创建分支节点
            对每个划分的子集
                递归调用创建决策树过程
        返回 分支节点

    根据生成的决策树，对待预测数据按照各个节点进行分类







开发机器学习程序的基本步骤：
1）收集数据
2）准备输入数据，准备合适的格式便于处理
3）分析输入数据，除异补漏
4）训练算法，根据输入样本训练算法，从中抽取知识或信息，建立模型
    对于无监督学习，因为没有目标变量，所以不需要训练算法
5）测试算法，取出适当的样本对建立的模型验证成功率，对于无监督学习要找其他方法验证
6）使用算法，利用建立的模型运用在实际环境，看能否正常工作

概述：
| 算法       | 优点                                                                           | 缺点                       | 适用数据范围   | 适用场景
| k-近邻算法 | 精度高，对异常值不敏感，无数据输入假定                                         | 计算复杂度高，空间复杂度高 | 数值型和标称型 | 手写识别
| 决策树     | 计算复杂度不高，输出结果容易理解，对中间值的缺失不敏感，可以处理不相关特征数据 | 可能会产生过度匹配问题     | 数值型和标称型 | 预测患者佩戴何种隐形眼镜





